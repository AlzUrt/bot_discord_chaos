import discord
from discord.ext import commands
import google.generativeai as genai
import os
from dotenv import load_dotenv
from collections import deque

# Charger les variables d'environnement
load_dotenv()

# Configuration
DISCORD_TOKEN = os.getenv('DISCORD_TOKEN')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

# Initialiser Gemini
genai.configure(api_key=GEMINI_API_KEY)

# Cr√©er le bot
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix='!', intents=intents)

# Historique des 10 derni√®res phrases g√©n√©r√©es
generated_history = deque(maxlen=10)

# Variable pour stocker le dernier prompt envoy√©
last_prompt = None

# Prompt de base pour !chaos
BASE_CHAOS_PROMPT = """G√©n√®re un paragraphe de 3 √† 4 phrases, sous forme d'histoire absurde qui encha√Æne des ordres √©tranges. Le texte doit √™tre d√©rangeant, choquant, absurde, mais chaque action doit avoir une justification interne, comme si tout ob√©issait √† une logique bizarre mais coh√©rente dans cet univers.
Le ton doit √™tre s√©rieux, comme si tu donnais des instructions vitales.

Les phrases doivent √™tre courtes, directes, non po√©tiques, et chaque phrase doit suivre le sch√©ma :
ordre absurde + justification √©trange mais logique dans ce monde.

Voici le style exact √† imiter :
¬´ Marche √† reculons pour inverser le cours du temps, c'est la seule mani√®re d'√©chapper aux heures qui te surveillent. Peins ton ombre en vert fluo pour qu'elle arr√™te de comploter contre toi. Abandonne tes souvenirs dans un micro-ondes en marche, ils doivent fondre pour cesser d'interf√©rer avec ta m√©moire. Envoie des lettres d'amour au vent avec des timbres en papier m√¢ch√©, car seuls les courants d'air savent encore te r√©pondre. ¬ª

Respecte ce ton, cette structure, et cette logique absurde mais coh√©rente. Pas de descriptions po√©tiques, pas de m√©taphores longues, juste des ordres √©tranges + explications √©tranges.

IMPORTANT: Les phrases pr√©c√©dentes suivantes ont D√âJ√Ä √©t√© g√©n√©r√©es. Tu DOIS absolument √©viter de les reproduire ou de g√©n√©rer quelque chose de similaire. Cr√©e quelque chose de compl√®tement diff√©rent :
{history}"""

def build_chaos_prompt():
    """Construit le prompt en incluant l'historique"""
    if generated_history:
        history_text = "\n".join(f"- {text}" for text in generated_history)
    else:
        history_text = "(Aucune phrase pr√©c√©dente)"
    
    return BASE_CHAOS_PROMPT.format(history=history_text)

@bot.event
async def on_ready():
    print(f'{bot.user} s\'est connect√© √† Discord!')

@bot.command(name='chaos')
async def chaos(ctx):
    """G√©n√®re un texte al√©atoire avec Gemini"""
    global last_prompt
    try:
        # Afficher que le bot est en train de traiter
        async with ctx.typing():
            # Construire le prompt avec l'historique
            current_prompt = build_chaos_prompt()
            
            # Enregistrer le dernier prompt
            last_prompt = current_prompt
            
            # Appeler l'API Gemini
            model = genai.GenerativeModel('gemini-2.0-flash')
            response = model.generate_content(
                current_prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.8,
                    max_output_tokens=300
                )
            )
            
            # Extraire le texte g√©n√©r√©
            generated_text = response.text
            
            # Ajouter le texte √† l'historique
            generated_history.append(generated_text)
            
            # Envoyer le message
            await ctx.send(generated_text)
            
    except Exception as e:
        await ctx.send(f"Erreur lors de la g√©n√©ration du texte: {str(e)}")


@bot.command(name='prompt')
async def prompt(ctx):
    """Affiche le dernier prompt qui a √©t√© envoy√© √† Gemini"""
    global last_prompt
    
    if last_prompt is None:
        await ctx.send("‚ùå Aucun prompt n'a √©t√© g√©n√©r√© pour le moment. Utilise `!chaos` d'abord.")
    else:
        # Discord a une limite de 2000 caract√®res par message
        max_length = 1900
        
        if len(last_prompt) <= max_length:
            # Si c'est court, on envoie directement
            await ctx.send(f"üìù **Dernier prompt envoy√©:**\n```\n{last_prompt}\n```")
        else:
            # Si c'est trop long, on d√©coupe en plusieurs messages
            await ctx.send("üìù **Dernier prompt envoy√©:** (en plusieurs parties)")
            
            # D√©couper le prompt en chunks
            chunks = [last_prompt[i:i + max_length] for i in range(0, len(last_prompt), max_length)]
            
            for i, chunk in enumerate(chunks, 1):
                await ctx.send(f"```\n{chunk}\n```")
                
            await ctx.send(f"‚úÖ Prompt affich√© en {len(chunks)} partie(s)")


# Lancer le bot
bot.run(DISCORD_TOKEN)